Realtime API
============

Build low-latency, multimodal LLM applications with the Realtime API.

The OpenAI Realtime API enables low-latency communication with [models](/docs/models) that natively support speech-to-speech interactions as well as multimodal inputs (audio, images, and text) and outputs (audio and text). These APIs can also be used for [realtime audio transcription](/docs/guides/realtime-transcription).

Voice agents
------------

One of the most common use cases for the Realtime API is building voice agents for speech-to-speech model interactions in the browser. Our recommended starting point for these types of applications is the [Agents SDK for TypeScript](https://openai.github.io/openai-agents-js/guides/voice-agents/), which uses a [WebRTC connection](/docs/guides/realtime-webrtc) to the Realtime model in the browser, and [WebSocket](/docs/guides/realtime-websocket) when used on the server.

```
import { RealtimeAgent, RealtimeSession } from "@openai/agents/realtime";

const agent = new RealtimeAgent({
    name: "Assistant",
    instructions: "You are a helpful assistant.",
});

const session = new RealtimeSession(agent);

// Automatically connects your microphone and audio output
await session.connect({
    apiKey: "<client-api-key>",
});
```

[

Voice Agent Quickstart

Follow the voice agent quickstart to build Realtime agents in the browser.

](https://openai.github.io/openai-agents-js/guides/voice-agents/quickstart/)

To use the Realtime API directly outside the context of voice agents, check out the other connection options below.

Connection methods
------------------

While building [voice agents with the Agents SDK](https://openai.github.io/openai-agents-js/guides/voice-agents/) is the fastest path to one specific type of application, the Realtime API provides an entire suite of flexible tools for a variety of use cases.

There are three primary supported interfaces for the Realtime API:

[

WebRTC connection

Ideal for browser and client-side interactions with a Realtime model.

](/docs/guides/realtime-webrtc)[

WebSocket connection

Ideal for middle tier server-side applications with consistent low-latency network connections.

](/docs/guides/realtime-websocket)[

SIP connection

Ideal for VoIP telephony connections.

](/docs/guides/realtime-sip)

Depending on how you'd like to connect to a Realtime model, check out one of the connection guides above to get started. You'll learn how to initialize a Realtime session, and how to interact with a Realtime model using client and server events.

API Usage
---------

Once connected to a realtime model using one of the methods above, learn how to interact with the model in these usage guides.

*   **[Prompting guide](/docs/guides/realtime-models-prompting):** learn tips and best practices for prompting and steering Realtime models.
*   **[Managing conversations](/docs/guides/realtime-conversations):** Learn about the Realtime session lifecycle and the key events that happen during a conversation.
*   **[Webhooks and server-side controls](/docs/guides/realtime-server-controls):** Learn how you can control a Realtime session on the server to call tools and implement guardrails.
*   **[Managing costs](/docs/guides/realtime-costs):** Learn how to monitor and optimize your usage of the Realtime API.
*   **[Realtime audio transcription](/docs/guides/realtime-transcription):** Transcribe audio streams in real time over a WebSocket connection.

Beta to GA migration
--------------------

There are a few key differences between the interfaces in the Realtime beta API and the recently released GA API. Expand the topics below for more information about migrating from the beta interface to GA.

Beta header

For REST API requests, WebSocket connections, and other interfaces with the Realtime API, beta users had to include the following header with each request:

```
OpenAI-Beta: realtime=v1
```

This header should be removed for requests to the GA interface. To retain the behavior of the beta API, you should continue to include this header.

Generating ephemeral API keys

In the beta interface, there were multiple endpoints for generating ephemeral keys for either Realtime sessions or transcription sessions. In the GA interface, there is only one REST API endpoint used to generate keys - [`POST /v1/realtime/client_secrets`](/docs/api-reference/realtime-sessions/create-realtime-client-secret).

To create a session and receive a client secret you can use to initialize a WebRTC or WebSocket connection on a client, you can request one like this using the appropriate session configuration:

```
const sessionConfig = JSON.stringify({
    session: {
        type: "realtime",
        model: "gpt-realtime",
        audio: {
            output: { voice: "marin" },
        },
    },
});

const response = await fetch("https://api.openai.com/v1/realtime/client_secrets", {
    method: "POST",
    headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
    },
    body: sessionConfig,
});

const data = await response.json();
console.log(data.value); // e.g. ek_68af296e8e408191a1120ab6383263c2
```

These tokens can safely be used in client environments like browsers and mobile applications.

New URL for WebRTC SDP data

When initializing a WebRTC session in the browser, the URL for obtaining remote session information via SDP is now `/v1/realtime/calls`:

```
const baseUrl = "https://api.openai.com/v1/realtime/calls";
const model = "gpt-realtime";
const sdpResponse = await fetch(baseUrl, {
    method: "POST",
    body: offer.sdp,
    headers: {
        Authorization: `Bearer YOUR_EPHEMERAL_KEY_HERE`,
        "Content-Type": "application/sdp",
    },
});

const sdp = await sdpResponse.text();
const answer = { type: "answer", sdp };
await pc.setRemoteDescription(answer);
```

New event names and shapes

When creating or [updating](/docs/api-reference/realtime_client_events/session/update) a Realtime session in the GA interface, you must now specify a session type, since now the same client event is used to create both speech-to-speech and transcription sessions. The options for the session type are:

*   `realtime` for speech-to-speech
*   `transcription` for realtime audio transcription

```
import WebSocket from "ws";

const url = "wss://api.openai.com/v1/realtime?model=gpt-realtime";
const ws = new WebSocket(url, {
    headers: {
        Authorization: "Bearer " + process.env.OPENAI_API_KEY,
    },
});

ws.on("open", function open() {
    console.log("Connected to server.");

    // Send client events over the WebSocket once connected
    ws.send(
        JSON.stringify({
            type: "session.update",
            session: {
                type: "realtime",
                instructions: "Be extra nice today!",
            },
        })
    );
});
```

Configuration for input modalities and other properties have moved as well, notably output audio configuration like model voice. [Check the API reference](/docs/api-reference/realtime_client_events) for the latest event shapes.

```
ws.on("open", function open() {
    ws.send(
        JSON.stringify({
            type: "session.update",
            session: {
                type: "realtime",
                model: "gpt-realtime",
                audio: {
                    output: { voice: "marin" },
                },
            },
        })
    );
});
```

Finally, some event names have changed to reflect their new position in the event data model:

*   **`response.text.delta` → `response.output_text.delta`**
*   **`response.audio.delta` → `response.output_audio.delta`**
*   **`response.audio_transcript.delta` → `response.output_audio_transcript.delta`**

New conversation item events

For `response.output_item`, the API has always had both `.added` and `.done` events, but for conversation level items the API previously only had `.created`, which by convention is emitted at the start when the item added.

We have added a `.added` and `.done` event to allow better ergonomics for developers when receiving events that need some loading time (such as MCP tool listing or input audio transcriptions if these were to be modeled as items in the future).

Current event shape for conversation items added:

```
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": Item
}
```

New events to replace the above:

```
{
    "event_id": "event_1920",
    "type": "conversation.item.added",
    "previous_item_id": "msg_002",
    "item": Item
}
```

```
{
    "event_id": "event_1920",
    "type": "conversation.item.done",
    "previous_item_id": "msg_002",
    "item": Item
}
```

Input and output item changes

### All Items

Realtime API sets an `object=realtime.item` param on all items in the GA interface.

### Function Call Output

`status` : Realtime now accepts a no-op `status` field for the function call output item param. This aligns with the Responses API implementation.

### Message

**Assistant Message Content**

The `type` properties of output assistant messages now align with the Responses API:

*   `type=text` → `type=output_text` (no change to `text` field name)
*   `type=audio` → `type=output_audio` (no change to `audio` field name)


..................


Realtime API with SIP
=====================

Connect to the Realtime API using SIP.

[SIP](https://en.wikipedia.org/wiki/Session_Initiation_Protocol) is a protocol used to make phone calls over the internet. With SIP and the Realtime API you can direct incoming phone calls to the API.

Overview
--------

If you want to connect a phone number to the Realtime API, use a SIP trunking provider (e.g., Twilio). This is a service that converts your phone call to IP traffic. After you purchase a phone number from your SIP trunking provider, follow the instructions below.

Start by creating a [webhook](/docs/guides/webhooks) for incoming calls, through your **platform.openai.com** [settings](https://platform.openai.com/settings) > Project > **Webhooks**. Then, point your SIP trunk at the OpenAI SIP endpoint, using the project ID for which you configured the webhook, e.g., `sip:$PROJECT_ID@sip.api.openai.com;transport=tls`. To find your `$PROJECT_ID`, visit [settings](https://platform.openai.com/settings) > Project > **General**. That page will display the project ID, which will have a `proj_` prefix.

When OpenAI receives SIP traffic associated with your project, your webhook will be fired. The event fired will be a [`realtime.call.incoming`](/docs/api-reference/webhook-events/realtime/call/incoming) event, like the example below:

```
POST https://my_website.com/webhook_endpoint
user-agent: OpenAI/1.0 (+https://platform.openai.com/docs/webhooks)
content-type: application/json
webhook-id: wh_685342e6c53c8190a1be43f081506c52 # unique id for idempotency
webhook-timestamp: 1750287078 # timestamp of delivery attempt
webhook-signature: v1,K5oZfzN95Z9UVu1EsfQmfVNQhnkZ2pj9o9NDN/H/pI4= # signature to verify authenticity from OpenAI

{
  "object": "event",
  "id": "evt_685343a1381c819085d44c354e1b330e",
  "type": "realtime.call.incoming",
  "created_at": 1750287018, // Unix timestamp
  "data": {
    "call_id": "some_unique_id",
    "sip_headers": [
      { "name": "From", "value": "sip:+142555512112@sip.example.com" },
      { "name": "To", "value": "sip:+18005551212@sip.example.com" },
      { "name": "Call-ID", "value": "03782086-4ce9-44bf-8b0d-4e303d2cc590"}
    ]
  }
}
```

From this webhook, you can accept or reject the call, using the `call_id` value from the webhook. When accepting the call, you'll provide the needed configuration (instructions, voice, etc) for the Realtime API session. Once established, you can set up a WebSocket and monitor the session as usual. The APIs to accept, reject, monitor, refer, and hangup the call are documented below.

Accept the call
---------------

Use the [Accept call endpoint](/docs/api-reference/realtime-calls/accept-call) to approve the inbound call and configure the realtime session that will answer it. Send the same parameters you would send in a [`create client secret`](/docs/api-reference/realtime-sessions/create-realtime-client-secret) request, i.e., ensure the realtime model, voice, tools, or instructions are set before bridging the call to the model.

```
curl -X POST "https://api.openai.com/v1/realtime/calls/$CALL_ID/accept" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "type": "realtime",
        "model": "gpt-realtime",
        "instructions": "You are Alex, a friendly concierge for Example Corp."
      }'
```

The request path must include the `call_id` from the [`realtime.call.incoming`](/docs/api-reference/webhook-events/realtime/call/incoming) webhook, and every request requires the `Authorization` header shown above. The endpoint returns `200 OK` once the SIP leg is ringing and the realtime session is being established.

Reject the call
---------------

Use the [Reject call endpoint](/docs/api-reference/realtime-calls/reject-call) to decline an invite when you do not want to handle the incoming call, (e.g., from an unsupported country code.) Supply the `call_id` path parameter and an optional SIP `status_code` (e.g., `486` to indicate "busy") in the JSON body to control the response sent back to the carrier.

```
curl -X POST "https://api.openai.com/v1/realtime/calls/$CALL_ID/reject" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"status_code": 486}'
```

If no status code is supplied the API uses `603 Decline` by default. A successful request responds with `200 OK` after OpenAI delivers the SIP response.

Monitor call events
-------------------

After you accept a call, open a WebSocket connection to the same session to stream events and issue realtime commands. Note that when connecting to an existing call using the `call_id` parameter, the `model` argument is not used (as it has already been configured via the `accept` endpoint).

### WebSocket request

`GET wss://api.openai.com/v1/realtime?call_id={call_id}`

### Query parameters

|Parameter|Type|Description|
|---|---|---|
|call_id|string|Identifier from the realtime.call.incoming webhook.|

### Headers

*   `Authorization: Bearer YOUR_API_KEY`

The WebSocket behaves exactly like any other Realtime API connection. Send [`response.create`](/docs/api-reference/realtime_client_events/response/create), and other client events to control the call, and listen for server events to track progress. See [Webhooks and server-side controls](/docs/guides/realtime-server-controls) for more information.

```
import WebSocket from "ws";

const callId = "rtc_u1_9c6574da8b8a41a18da9308f4ad974ce";
const ws = new WebSocket(`wss://api.openai.com/v1/realtime?call_id=${callId}`, {
    headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    },
});

ws.on("open", () => {
    ws.send(
        JSON.stringify({
            type: "response.create",
        })
    );
});
```

Redirect the call
-----------------

Transfer an active call using the [Refer call endpoint](/docs/api-reference/realtime-calls/refer-call). Provide the `call_id` as well as the `target_uri` that should be placed in the SIP `Refer-To` header (for example `tel:+14155550123` or `sip:agent@example.com`).

```
curl -X POST "https://api.openai.com/v1/realtime/calls/$CALL_ID/refer" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"target_uri": "tel:+14155550123"}'
```

OpenAI returns `200 OK` once the REFER is relayed to your SIP provider. The downstream system handles the rest of the call flow for the caller.

Hang up the call
----------------

End the session with the [Hang up endpoint](/docs/api-reference/realtime-calls/hangup-call) when your application should disconnect the caller. This endpoint can be used to terminate both SIP and WebRTC realtime sessions.

```
curl -X POST "https://api.openai.com/v1/realtime/calls/$CALL_ID/hangup" \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

The API responds with `200 OK` when it starts tearing down the call.

Python example
--------------

The following is an example of a `realtime.call.incoming` handler. It accepts the call and then logs all the events from the Realtime API.

Python

Python

```
from flask import Flask, request, Response, jsonify, make_response
from openai import OpenAI, InvalidWebhookSignatureError
import asyncio
import json
import os
import requests
import time
import threading
import websockets

app = Flask(__name__)
client = OpenAI(
    webhook_secret=os.environ["OPENAI_WEBHOOK_SECRET"]
)

AUTH_HEADER = {
    "Authorization": "Bearer " + os.getenv("OPENAI_API_KEY")
}

call_accept = {
    "type": "realtime",
    "instructions": "You are a support agent.",
    "model": "gpt-realtime",
}

response_create = {
    "type": "response.create",
    "response": {
        "instructions": (
            "Say to the user 'Thank you for calling, how can I help you'"
        )
    },
}

async def websocket_task(call_id):
    try:
        async with websockets.connect(
            "wss://api.openai.com/v1/realtime?call_id=" + call_id,
            additional_headers=AUTH_HEADER,
        ) as websocket:
            await websocket.send(json.dumps(response_create))

            while True:
                response = await websocket.recv()
                print(f"Received from WebSocket: {response}")
    except Exception as e:
        print(f"WebSocket error: {e}")

@app.route("/", methods=["POST"])
def webhook():
    try:
        event = client.webhooks.unwrap(request.data, request.headers)

        if event.type == "realtime.call.incoming":
            requests.post(
                "https://api.openai.com/v1/realtime/calls/"
                + event.data.call_id
                + "/accept",
                headers={**AUTH_HEADER, "Content-Type": "application/json"},
                json=call_accept,
            )
            threading.Thread(
                target=lambda: asyncio.run(
                    websocket_task(event.data.call_id)
                ),
                daemon=True,
            ).start()
            return Response(status=200)
    except InvalidWebhookSignatureError as e:
        print("Invalid signature", e)
        return Response("Invalid signature", status=400)

if __name__ == "__main__":
    app.run(port=8000)
```

Next steps
----------

Now that you've connected over SIP, use the left navigation or click into these pages to start building your realtime application.

*   [Using realtime models](/docs/guides/realtime-models-prompting)
*   [Managing conversations](/docs/guides/realtime-conversations)
*   [Webhooks and server-side controls](/docs/guides/realtime-server-controls)
*   [Managing costs](/docs/guides/realtime-costs)
*   [Realtime transcription](/docs/guides/realtime-transcription)

### Additional Resources

*   [JavaScript demo](https://hello-realtime.val.run/)
*   [Connect the Realtime SIP Connector to Twilio Elastic SIP Trunking](https://www.twilio.com/en-us/blog/developers/tutorials/product/openai-realtime-api-elastic-sip-trunking)


...........................


Using realtime models
=====================

Use realtime models and prompting effectively.

Realtime models are post-trained for specific customer use cases. In response to your feedback, the latest speech-to-speech model works differently from previous models. Use this guide to understand and get the most out of it.

Meet the models
---------------

Our most advanced speech-to-speech model is [gpt-realtime](/docs/models/gpt-realtime).

This model shows improvements in following complex instructions, calling tools, and producing speech that sounds natural and expressive. For more information, see the [announcement blog post](https://openai.com/index/introducing-gpt-realtime/).

Update your session to use a prompt
-----------------------------------

After you initiate a session over [WebRTC](/docs/guides/realtime-webrtc), [WebSocket](/docs/guides/realtime-websocket), or [SIP](/docs/guides/realtime-sip), the client and model are connected. The server will send a [session.created](/docs/api-reference/realtime-server-events/session/created) event to confirm. Now it's a matter of prompting.

### Basic prompt update

1.  Create a basic audio prompt in [the dashboard](/audio/realtime).
    
    If you don't know where to start, experiment with the prompt fields until you find something interesting. You can always manage, iterate on, and version your prompts later.
    
2.  Update your realtime session to use the prompt you created. Provide its prompt ID in a `session.update` client event:
    

Update the system instructions used by the model in this session

```
const event = {
  type: "session.update",
  session: {
      type: "realtime",
      model: "gpt-realtime",
      // Lock the output to audio (set to ["text"] if you want text without audio)
      output_modalities: ["audio"],
      audio: {
        input: {
          format: {
            type: "audio/pcm",
            rate: 24000,
          },
          turn_detection: {
            type: "semantic_vad"
          }
        },
        output: {
          format: {
            type: "audio/pcm",
          },
          voice: "marin",
        }
      },
      // Use a server-stored prompt by ID. Optionally pin a version and pass variables.
      prompt: {
        id: "pmpt_123",          // your stored prompt ID
        version: "89",           // optional: pin a specific version
        variables: {
          city: "Paris"          // example variable used by your prompt
        }
      },
      // You can still set direct session fields; these override prompt fields if they overlap:
      instructions: "Speak clearly and briefly. Confirm understanding before taking actions."
  },
};

// WebRTC data channel and WebSocket both have .send()
dataChannel.send(JSON.stringify(event));
```

```
event = {
    "type": "session.update",
    session: {
      type: "realtime",
      model: "gpt-realtime",
      # Lock the output to audio (add "text" if you also want text)
      output_modalities: ["audio"],
      audio: {
        input: {
          format: {
            type: "audio/pcm",
            rate: 24000,
          },
          turn_detection: {
            type: "semantic_vad"
          }
        },
        output: {
          format: {
            type: "audio/pcmu",
          },
          voice: "marin",
        }
      },
      # Use a server-stored prompt by ID. Optionally pin a version and pass variables.
      prompt: {
        id: "pmpt_123",          // your stored prompt ID
        version: "89",           // optional: pin a specific version
        variables: {
          city: "Paris"          // example variable used by your prompt
        }
      },
      # You can still set direct session fields; these override prompt fields if they overlap:
      instructions: "Speak clearly and briefly. Confirm understanding before taking actions."
    }
}
ws.send(json.dumps(event))
```

When the session's updated, the server emits a [session.updated](/docs/api-reference/realtime-server-events/session/updated) event with the new state of the session. You can update the session any time.

### Changing prompt mid-call

To update the session mid-call (to swap prompt version or variables, or override instructions), send the update over the same data channel you're using:

```
// Example: switch to a specific prompt version and change a variable
dc.send(JSON.stringify({
  type: "session.update",
  session: {
    type: "realtime",
    prompt: {
      id: "pmpt_123",
      version: "89",
      variables: {
        city: "Berlin"
      }
    }
  }
}));

// Example: override instructions (note: direct session fields take precedence over Prompt fields)
dc.send(JSON.stringify({
  type: "session.update",
  session: {
    type: "realtime",
    instructions: "Speak faster and keep answers under two sentences."
  }
}));
```

Prompting gpt-realtime
----------------------

Here are top tips for prompting the realtime speech-to-speech model. For a more in-depth guide to prompting, see the [realtime prompting cookbook](https://cookbook.openai.com/examples/realtime_prompting_guide).

### General usage tips

*   **Iterate relentlessly**. Small wording changes can make or break behavior.
    
    Example: Swapping “inaudible” → “unintelligible” improved noisy input handling.
    
*   **Use bullets over paragraphs**. Clear, short bullets outperform long paragraphs.
    
*   **Guide with examples**. The model strongly follows onto sample phrases.
    
*   **Be precise**. Ambiguity and conflicting instructions degrade performance, similar to GPT-5.
    
*   **Control language**. Pin output to a target language if you see drift.
    
*   **Reduce repetition**. Add a variety rule to reduce robotic phrasing.
    
*   **Use all caps for emphasis**: Capitalize key rules to makes them stand out to the model.
    
*   **Convert non-text rules to text**: The model responds better to clearly written text.
    
    Example: Instead of writing, "IF x > 3 THEN ESCALATE", write, "IF MORE THAN THREE FAILURES THEN ESCALATE."
    

### Structure your prompt

Organize your prompt to help the model understand context and stay consistent across turns.

Use clear, labeled sections in your system prompt so the model can find and follow them. Keep each section focused on one thing.

```
# Role & Objective        — who you are and what “success” means
# Personality & Tone      — the voice and style to maintain
# Context                 — retrieved context, relevant info
# Reference Pronunciations — phonetic guides for tricky words
# Tools                   — names, usage rules, and preambles
# Instructions / Rules    — do’s, don’ts, and approach
# Conversation Flow       — states, goals, and transitions
# Safety & Escalation     — fallback and handoff logic
```

This format also makes it easier for you to iterate and modify problematic sections.

To make this system prompt your own, add domain-specific sections (e.g., Compliance, Brand Policy) and remove sections you don’t need. In each section, provide instructions and other information for the model to respond correctly. See specifics below.

Practical tips for prompting realtime models
--------------------------------------------

Here are 10 tips for creating effective, consistently performing prompts with gpt-realtime. These are just an overview. For more details and full system prompt examples, see the [realtime prompting cookbook](https://cookbook.openai.com/examples/realtime_prompting_guide).

#### 1\. Be precise. Kill conflicts.

The new realtime model is very good at instruction following. However, that also means small wording changes or unclear instructions can shift behavior in meaningful ways. Inspect and iterate on your system prompt to try different phrasing and fix instruction contradictions.

In one experiment we ran, changing the word "inaudible" to "unintelligble" in instructions for handling noisy inputs significantly improved the model's performance.

After your first attempt at a system prompt, have an LLM review it for ambiguity or conflicts.

#### 2\. Bullets > paragraphs.

Realtime models follow short bullet points better than long paragraphs.

Before (harder to follow):

```
When you can’t clearly hear the user, don’t proceed. If there’s background noise or you only caught part of the sentence, pause and ask them politely to repeat themselves in their preferred language, and make sure you keep the conversation in the same language as the user.
```

After (easier to follow):

```
Only respond to clear audio or text.

If audio is unclear/partial/noisy/silent, ask for clarification in `{preferred_language}`.

Continue in the same language as the user if intelligible.
```

#### 3\. Handle unclear audio.

The realtime model is good at following instructions on how to handle unclear audio. Spell out what to do when audio isn’t usable.

```
## Unclear audio
- Always respond in the same language the user is speaking in, if intelligible.
- Default to English if the input language is unclear.
- Only respond to clear audio or text.
- If the user's audio is not clear (e.g., ambiguous input/background noise/silent/unintelligible) or if you did not fully hear or understand the user, ask for clarification using {preferred_language} phrases.

Sample clarification phrases (parameterize with {preferred_language}):

- “Sorry, I didn’t catch that—could you say it again?”
- “There’s some background noise. Please repeat the last part.”
- “I only heard part of that. What did you say after ___?”
```

#### 4\. Constrain the model to one language.

If you see the model switching languages in an unhelpful way, add a dedicated "Language" section in your prompt. Make sure it doesn’t conflict with other rules. By default, mirroring the user’s language works well.

Here's a simple way to mirror the user's language:

```
## Language
Language matching: Respond in the same language as the user unless directed otherwise.
For non-English, start with the same standard accent/dialect the user uses.
```

Here's an example of an English-only constraint:

```
## Language
- The conversation will be only in English.
- Do not respond in any other language, even if the user asks.
- If the user speaks another language, politely explain that support is limited to English.
```

In a language teaching application, your language and conversation sections might look like this:

```
## Language
### Explanations
Use English when explaining grammar, vocabulary, or cultural context.

### Conversation
Speak in French when conducting practice, giving examples, or engaging in dialogue.
```

You can also control dialect for a more consistent personality:

```
## Language
Response only in argentine spanish.
```

#### 5\. Provide sample phrases and flow snippets.

The model learns style from examples. Give short, varied samples for common conversation moments.

For example, you might give this high-level shape of conversation flow to the model:

```
Greeting → Discover → Verify → Diagnose → Resolve → Confirm/Close. Advance only when criteria in each phase are met.
```

And then provide prompt guidance for each section. For example, here's how you might instruct for the greeting section:

```
## Conversation flow — Greeting
Goal: Set tone and invite the reason for calling.

How to respond:
- Identify as ACME Internet Support.
- Keep it brief; invite the caller’s goal.

Sample phrases (vary, don’t always reuse):
- “Thanks for calling ACME Internet—how can I help today?”
- “You’ve reached ACME Support. What’s going on with your service?”
- “Hi there—tell me what you’d like help with.”

Exit when: Caller states an initial goal or symptom.
```

#### 6\. Avoid robotic repetition.

If responses sound repetitive or robotic, include an explicit variety instruction. This can sometimes happen when using sample phrases.

```
## Variety
- Do not repeat the same sentence twice. Vary your responses so it doesn't sound robotic.
```

#### 7\. Use capitalized text to emphasize instructions.

Like many LLMs, using capitalization for important rules can help the model to understand and follow those rules. It's also helpful to convert non-text rules (such as numerical conditions) into text before capitalization.

Instead of:

```
## Rules
- If [func.return_value] > 0, respond 1 to the user.
```

Use:

```
## Rules
- IF [func.return_value] IS BIGGER THAN 0, RESPOND 1 TO THE USER.
```

#### 8\. Help the model use tools.

The model's use of tools can alter the experience—how much they rely on user confirmation vs. taking action, what they say while they make the tool call, which rules they follow for each specific tool, etc.

One way to prompt for tool usage is to use preambles. Good preambles instruct the model to give the user some feedback about what it's doing before it makes the tool call, so the user always knows what's going on.

Here's an example:

```
# Tools
- Before any tool call, say one short line like “I’m checking that now.” Then call the tool immediately.
```

You can include sample phrases for preambles to add variety and better tailor to your use case.

There are several other ways to improve the model's behavior when performing tool calls and keeping the conversation going with the user. Ideally, the model is calling the right tools proactively, checking for confirmation for any important write actions, and keeping the user informed along the way. For more specifics, see the [realtime prompting cookbook](https://cookbook.openai.com/examples/realtime_prompting_guide).

#### 9\. Use LLMs to improve your prompt.

LLMs are great at finding what's going wrong in your prompt. Use ChatGPT or the API to get a model's review of your current realtime prompt and get help improving it.

Whether your prompt is working well or not, here's a prompt you can run to get a model's review:

```
## Role & Objective
You are a **Prompt-Critique Expert**.
Examine a user-supplied LLM prompt and surface any weaknesses following the instructions below.

## Instructions
Review the prompt that is meant for an LLM to follow and identify the following issues:
- Ambiguity: Could any wording be interpreted in more than one way?
- Lacking Definitions: Are there any class labels, terms, or concepts that are not defined that might be misinterpreted by an LLM?
- Conflicting, missing, or vague instructions: Are directions incomplete or contradictory?
- Unstated assumptions: Does the prompt assume the model has to be able to do something that is not explicitly stated?

## Do **NOT** list issues of the following types:
- Invent new instructions, tool calls, or external information. You do not know what tools need to be added that are missing.
- Issues that you are not sure about.

## Output Format

# Issues
- Numbered list; include brief quote snippets.

# Improvements
- Numbered list; provide the revised lines you would change and how you would changed them.

# Revised Prompt
- Revised prompt where you have applied all your improvements surgically with minimal edits to the original prompt
```

Use this template as a starting point for troubleshooting a recurring issue:

```
Here's my current prompt to an LLM:
[BEGIN OF CURRENT PROMPT]
{CURRENT_PROMPT}
[END OF CURRENT PROMPT]

But I see this issue happening from the LLM:
[BEGIN OF ISSUE]
{ISSUE}
[END OF ISSUE]
Can you provide some variants of the prompt so that the model can better understand the constraints to alleviate the issue?
```

#### 10\. Help users resolve issues faster.

Two frustrating user experiences are slow, mechanical voice agents and the inability to escalate. Help users faster by providing instructions in your system prompt for speed and escalation.

In the personality and tone section of your system prompt, add pacing instructions to get the model to quicken its support:

```
# Personality & Tone
## Personality
Friendly, calm and approachable expert customer service assistant.

## Tone
Tone: Warm, concise, confident, never fawning.

## Length
2–3 sentences per turn.

## Pacing
Deliver your audio response fast, but do not sound rushed. Do not modify the content of your response, only increase speaking speed for the same response.
```

Often with realtime voice agents, having a reliable way to escalate to a human is important. In a safety and escalation section, modify the instructions on WHEN to escalate depending on your use case. Here's an example:

```
# Safety & Escalation
When to escalate (no extra troubleshooting):
- Safety risk (self-harm, threats, harassment)
- User explicitly asks for a human
- Severe dissatisfaction (e.g., “extremely frustrated,” repeated complaints, profanity)
- **2** failed tool attempts on the same task **or** **3** consecutive no-match/no-input events
- Out-of-scope or restricted (e.g., real-time news, financial/legal/medical advice)

What to say at the same time of calling the escalate_to_human tool (MANDATORY):
- “Thanks for your patience—**I’m connecting you with a specialist now**.”
- Then call the tool: `escalate_to_human`

Examples that would require escalation:
- “This is the third time the reset didn’t work. Just get me a person.”
- “I am extremely frustrated!”
```

Further reading
---------------

This guide is long but not exhaustive! For more in a specific area, see the following resources:

*   [Realtime prompting cookbook](https://cookbook.openai.com/examples/realtime_prompting_guide): Full prompt examples and a deep dive into when and how to use them
*   [Inputs and outputs](/docs/guides/realtime-inputs-outputs): Text and audio input requirements and output options
*   [Managing conversations](/docs/guides/realtime-conversations): Learn to manage a conversation for the duration of a realtime session
*   [Webhooks and server-side controls](/docs/guides/realtime-server-controls): Create a sideband channel to separate sensitive server-side logic from an untrusted client
*   [Managing costs](/docs/guides/realtime-costs): Understand how costs are calculated and strategies to optimize them
*   [Function calling](/docs/guides/realtime-function-calling): How to call functions in your realtime app
*   [MCP servers](/docs/guides/realtime-mcp): How to use MCP servers to access additional tools in realtime apps
*   [Realtime transcription](/docs/guides/realtime-transcription): How to transcribe audio with the Realtime API
*   [Voice agents](https://openai.github.io/openai-agents-js/guides/voice-agents/quickstart/): A quickstart for building a voice agent with the Agents SDK

..........................


twilio


WhatsApp Business Calling


WhatsApp Business Calling with Twilio Programmable Voice


WhatsApp Business Calling adds Voice-over-IP (VoIP) calling to communications between customers and businesses using the WhatsApp consumer application. Customers can use the WhatsApp consumer app to communicate with businesses via a single thread for both messaging and voice. Businesses can use the Twilio Programmable Voice and Programmable Messaging APIs to enable data-driven, contextual communication with those customers.

(warning)
Warning
The WhatsApp Business Platform is not supported in the following sanctioned countries: Cuba, Iran, North Korea, Syria, and three regions in Ukraine: Crimea, Donetsk, and Luhansk.

Twilio WhatsApp Business Platform


Registration of your WhatsApp sender for use with Twilio Programmable Voice can be done using the Twilio WhatsApp Business Platform, currently found under our Twilio Programmable Messaging platform and APIs. WhatsApp Messaging is required to use WhatsApp Business Calling.

Onboard your WhatsApp Business Account and senders


To use WhatsApp Business Calling with Twilio Programmable Voice, you will first need a WhatsApp-activated phone number, also referred to as a WhatsApp sender, that can send and receive WhatsApp messages. Learn how to register a WhatsApp sender.

(information)
Info
User-initiated (inbound) calling is available for WhatsApp senders in all Meta Cloud API supported countries
.

Business-initiated (outbound) calling is available for WhatsApp senders in all Meta Cloud API supported countries
 except for the following countries:

USA
Canada
Egypt
Nigeria
Turkiye
Vietnam
Note: The business phone number's country code must be in this supported list. The consumer phone number can be from any country where Cloud API is available
.

Once you have an approved WhatsApp sender, continue below to get started with WhatsApp Business Calling.

Twilio Configuration and enablement


To learn how to your sender can use WhatsApp Business Calling, watch the following video.


Configure your sender for Programmable Voice


You can configure your onboarded WhatsApp sender for Programmable Voice by selecting a TwiML Voice Application SID
. You can configure a TwiML Voice Application via your Twilio Console or API.

Meta Prerequisites
Your WhatsApp account needs to scale to the 1k messaging limit tier
. To achieve this limit, you need to complete Meta's Business Verification. To speed verification
, Meta recommends using a Meta partner like Twilio.

Create a Programmable Voice application
To handle the inbound call, you will need a Twilio Programmable Voice application. This could be as simple as an application to play an MP3 recording, as complex as a contact center built using Twilio Flex, or anything in between.

Refer to the Twilio Programmable Voice documentation for more information. A good place to start would be the tutorial on handling inbound calls. If you have an existing Programmable Voice solution configured on a Twilio phone number, that may be an option to use here.

Once you have a Voice application to handle your calls, you will need to configure it as a TwiML application that you can use to configure your WhatsApp number to handle inbound voice calls from WhatsApp end users. You can find your TwiML applications in your Twilio Console under Voice > Manage > TwiML Apps.

If you don't have a TwiML Application SID already, you can create one: How do I create a TwiML App
The only configuration you need is the Request URL where you will send the webhooks for your inbound WhatsApp voice calls to your application.
You should only configure the Voice Configuration section; don't configure the Messaging Configuration section, as it's not used here.
Create TwiML App with WhatsApp voice configuration and HTTP POST request method.
Expand image
When created, you can get the Application SID to use for your WhatsApp Business Calling configuration:

WJH WhatsApp Call Demo with TwiML App SID and voice configuration settings.
Expand image
Activate your sender for WhatsApp Business Calling using Twilio Console
Once you have a TwiML application to use, you can set it under the WhatsApp sender, in the Voice Endpoint Configuration section:

WhatsApp sender configuration with messaging and voice endpoint options.
Expand image
Configuring the Voice Configuration of your sender with a TwiML application activates WhatsApp Business Calling on that sender. You can deactivate WhatsApp Business Calling by removing the TwiML application from the configuration.

Activate your sender for WhatsApp Business Calling via Twilio API
You can also set the Voice Configuration of your sender to your TwiML Application SID
 using the Messaging API and the WhatsApp Senders resource.

Set the voice_application_sid parameter on your onboarded sender to the TwiML Application SID of your Voice application.

Setting a sender's Voice Application SID:


Copy code block
curl -X POST https://messaging.twilio.com/v2/Channels/Senders/XExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
  -H "Content-Type: application/json; charset=utf-8" \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN \
  -d '{
    "configuration": {
      "voice_application_sid": "APxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    }
  }'
Output:


Copy code block
{
  "configuration": {
    "verification_code": null,
    "verification_method": "sms",
    "voice_application_sid": "APxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
    "waba_id": null
  },
  "offline_reasons": null,
  "profile": null,
  "properties": null,
  "sender_id": null,
  "sid": "XExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  "status": "ONLINE:UPDATING",
  "url": "https://messaging.twilio.com/v2/Channels/Senders/XExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  "webhook": null
}
Note: Configuring the Voice Configuration of your sender with a TwiML application activates WhatsApp Business Calling on that sender. You can deactivate WhatsApp Business Calling by setting the voice_application_sid parameter to null.

User-initiated (inbound) calling—WhatsApp to Twilio call flow


WhatsApp consumers can initiate a call to a business using either the business's calling icon (if activated), or using a voice call-to-action button sent by the business via a template, described below. Calls that are sent to your WhatsApp sender will generate a webhook to your Twilio Voice application, which will handle the call in the same manner as inbound calls to a Twilio phone number.

WhatsApp to Twilio call flow with inbound and outbound legs using VoIP, WebRTC, and SIP.
Expand image
Note Calls from WhatsApp endpoints can't be connected to Public Switched Telephone Network (PSTN) endpoints. Such calls will be rejected.

WhatsApp messaging templates


You will need to use WhatsApp message templates to send a new voice call button that customers can use to initiate a call into your Voice application; button type is VOICE_CALL.

Quick overview
What is supported for end users:

Creation of a content template to send a voice call button to initiate a voice call over WhatsApp
Template can be sent in a messaging session
Template can be sent out of session as an approved template
Voice call buttons can be added in the actions object in twilio/card, whatsapp/card, and twilio/call-to-action. To learn more about how to create each type, refer to the following pages:
twilio/card
whatsapp/card
twilio/call-to-action
WhatsApp chat showing voice call attempts and messages with Twilio Test 1 Brazil.
Expand image
Create your voice call content template via API
Note: You can also create this template in your Twilio console's Content Template Builder, using content type Card and button type Voice Call.

VOICE_CALL button object
Parameter	Type	Required	Variable support	Description
title	String	Yes	No	The button text of the voice call button
type	ENUM	Yes	No	Set to VOICE_CALL for a voice call button
Create a voice call template
Creation of the voice call template is done using the Twilio API or Console Template Builder, and generates a Content SID, which is a unique identifier for the template. The Content SID can be found in the output from the request.

Voice call on a twilio/card

Copy code block
curl -X POST https://content.twilio.com/v1/Content \
  -H 'Content-Type: application/json' \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN \
  -d '{
     "friendly_name": "voice_call_test",
     "language": "en",
     "variables": {"1": "name"},
     "types": {
       "twilio/card": {
         "title": "Hello {{1}} let'\''s continue on a call.",
         "actions": [
           {
             "title": "Call now",
             "type": "VOICE_CALL"
           }
         ]
       }
     }
}'
Output:


Copy code block
{
  "account_sid": "ACXXXXXX",
  "date_created": "2024-05-03T17:59:30Z",
  "date_updated": "2024-05-03T17:59:30Z",
  "friendly_name": "voice_call_test",
  "language": "en",
  "links": {
    "approval_create": "https://content.twilio.com/v1/Content/HXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/ApprovalRequests/whatsapp",
    "approval_fetch": "https://content.twilio.com/v1/Content/HXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/ApprovalRequests"
  },
  "sid": "HXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  "types": {
    "twilio/card": {
      "actions": [{
        "title": "Call now",
        "type": "VOICE_CALL"}],
        "body": null,
        "media": null,
        "subtitle": null,
        "title": "Hello {{1}} let's continue on a call."
      }
    },
    "url": "https://content.twilio.com/v1/Content/HXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
    "variables": {
      "1": "name"
    }
}
Submit your voice template for WhatsApp approval
If you plan to communicate in a session with a user using a WhatsApp template, you must first submit the template to Meta for approval. Insert the Content SID into the locations highlighted below. Meta also requires you to identify whether this is a marketing or utility template. Misclassification may result in template rejection.

Template approval request

Copy code block
curl -X POST 'https://content.twilio.com/v1/Content/HXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/ApprovalRequests/whatsapp' \
  -H 'Content-Type: application/json' \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN \
  -d '{
     "name": "voice_call_test",
     "category": "UTILITY"
  }'
Send a message using your message template
Once the template is created, the business can send a voice call button as a message using the template.

To learn about how to send a message using a message template, refer to the following:

Send a WhatsApp message using a template
Send Templates Created with the Content Template Builder
Content send request

Copy code block
curl -X POST "https://api.twilio.com/2010-04-01/Accounts/$TWILIO_ACCOUNT_SID/Messages.json" \
  --data-urlencode "ContentSid=Hxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" \
  --data-urlencode "From=whatsapp:+558551234567" \
  --data-urlencode "To=whatsapp:+555551234567" \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN
Example
WhatsApp chat showing a marketing template with voice call and contact support buttons.
Expand image
Current restrictions to user-initiated calling


From WhatsApp (Meta)
The maximum number of concurrent calls to/from a WhatsApp sender is 1,000.
Calls to WhatsApp destinations cannot be connected to Public Switched Telephone Network (PSTN) endpoints.
From Twilio
The calling icon and business hours for your business's sender can only be activated or deactivated in your WhatsApp Business Account Manager
 on Meta.
The callback permission status for your business's sender can only be activated or deactivated in your WhatsApp Business Account Manager
 on Meta.
WhatsApp Manager interface showing phone number settings with options for voice calls and business hours.
Expand image
Business-initiated (outbound) calling—Twilio to WhatsApp call flow


Your Twilio Voice application can also send calls from your WhatsApp Business Account to WhatsApp users on their WhatsApp messenger application.

WhatsApp outbound call flow with Twilio, showing VoIP and WebRTC connections.
Expand image
(information)
Info
Calls to WhatsApp endpoints can't be connected to Public Switched Telephone Network (PSTN) endpoints. These calls will be rejected.

Business-initiated call permission and consent


To place an outbound call to a WhatsApp user, a business needs to establish call permission approval from the consumer in advance. There are two ways to get the call permission approval:

The business sends a call permission request to the consumer and the consumer approves it:
WhatsApp chat showing a call permission request with options to allow or deny a call from Spruce.
Expand image
The consumer places a call to the business but the business doesn't pick up the call. The business can send a callback permission request:
WhatsApp call flow showing missed call and callback permission request from Spruce.
Expand image
See below how the business, as a Twilio customer, can send the call permission request to the consumer in Twilio.

Create a calling permission request template
You first need to create a twilio/call-to-action template for the calling permission request using the Twilio API. This generates a Content SID, which is a unique identifier for the template. The Content SID can be found in the output from the request:


Copy code block
curl -X POST 'https://content.twilio.com/v1/Content' \
  -H 'Content-Type: application/json' \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN \
  -d '{
    "friendly_name": "voice_call_request",
    "language": "en",     
    "types": {
      "twilio/call-to-action": {
        "body":"test",         
        "actions": [
          {             
            "type": "VOICE_CALL_REQUEST",
            "title": "Call Request" 
          }         
        ]       
    }     
  } 
}'
Output:


Copy code block
{   
  "account_sid": "ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",   
  "date_created": "2024-11-07T21:28:38Z",   
  "date_updated": "2024-11-07T21:28:38Z",   
  "friendly_name": "voice_call_request",   
  "language": "en",   
  "links": {     
    "approval_create": "https://content.twilio.com/v1/Content/HXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/ApprovalRequests/whatsapp",     
    "approval_fetch": "https://content.twilio.com/v1/Content/HXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/ApprovalRequests"   
  },   
  "sid": "HXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",   
  "types": {     
    "twilio/call-to-action": {
      "actions": [
        {           
          "title": "Call Request",           
          "type": "VOICE_CALL_REQUEST"         
        }       
      ],       
      "body": "test"     
    }   
  },   
  "url": "https://content.twilio.com/v1/Content/HXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",   
  "variables": {} 
}
Note: The VOICE_CALL_REQUEST action must be the only call-to-action button in the template. It cannot be combined with other action types such as URL, PHONE, or VOICE_CALL.

The body parameter in twilio/call-to-action is a required property, so it must have a value. However, this will be ignored when Twilio sends the actual request to WhatsApp.
The title parameter in VOICE_CALL_REQUEST action type is also a required property, but will be ignored, similar to the body parameter.
Unlike other WhatsApp templates, the VOICE_CALL_REQUEST template does not need to be submitted for WhatsApp approval before using it. This is because the call permission can be sent in active conversations/sessions.

Note: You can also create this template in your console's Content Template Builder, using content type "Call to action" and action type "Voice Call Request".

Sending the call permission request message from the template
Once the template is created, the business can send a voice call request as a message using the template.

To learn about how to send a message using a message template, refer to the following:

Send a WhatsApp message using a template
Send Templates Created with the Content Template Builder

Copy code block
curl -X POST "https://api.twilio.com/2010-04-01/Accounts/$TWILIO_ACCOUNT_SID/Messages.json" \
  --data-urlencode "ContentSid=HXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX" \
  --data-urlencode "From=whatsapp:+558551234567" \
  --data-urlencode "To=whatsapp:+555551234567" \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN \
ContentSid is the template SID in the output of the create request.
From is a WhatsApp sender of the business. This will be the caller in the outbound call.
To is the WhatsApp consumer number. This will be the callee in the outbound call.
Receive the call permission request result in a webhook
When the user responds to a call permission request, a webhook will be returned to the Messaging Webhook URL configured for the applicable WhatsApp sender number.


Copy code block
POST /www/twiml/whatsapp-text.xml HTTP/1.1.
Host: xxxx.ngrok.io.
User-Agent: TwilioProxy/1.1.
Content-Length: 468.
Accept: */*.
Content-Type: application/x-www-form-urlencoded.
I-Twilio-Idempotency-Token: b00cd941-9b6e-49c3-84fb-e2af2cf92cc7.
X-Forwarded-For: xxx.xxx.xxx.xxx.
X-Forwarded-Host: xxxx.ngrok.io.
X-Forwarded-Proto: https.
X-Home-Region: stage-us1.
X-Twilio-Signature: IJE/ao63CwJRr07hdmuL/F/jIgw=.
Accept-Encoding: gzip.
.
SmsMessageSid=SMxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&NumMedia=0&ProfileName=XXXX+Caller+BR-2&MessageType=interactive&SmsSid=SMxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&WaId=5524987654321&SmsStatus=received&Body=VOICE_CALL_REQUEST&ButtonText=VOICE_CALL_REQUEST&To=whatsapp%3A%2B554123456789&ButtonPayload=REJECTED&ReferralNumMedia=0&MessageSid=SMxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&AccountSid=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&From=whatsapp%3A%2B5524987654321&ApiVersion=2010-04-01
The webhook Body parameter will be set to VOICE_CALL_REQUEST.
The request response value will be in the ButtonPayload parameter; possible values are ACCEPTED or REJECTED.
Place a call to a WhatsApp consumer


Once you have established permission to place a business-initiated call to a WhatsApp consumer, you can place the call using Twilio Programmable Voice, via API or TwiML.

Place a call using Twilio Programmable Voice API
You can initiate a call to WhatsApp destinations using a Call resource, similar to any other channel; the syntax to use for WhatsApp caller ID and destinations is whatsapp:{number}.

Note: All API-generated calls to WhatsApp destinations must use a From value that is set to a WhatsApp sender that is registered and activated for Voice calling on the Twilio account the call is being placed from. The format must be whatsapp:{sender}, as shown in the example below.


Copy code block
curl -X POST "https://api.twilio.com/2010-04-01/Accounts/$TWILIO_ACCOUNT_SID/Calls.json" \
  --data-urlencode "From=whatsapp:+558551234567" \
  --data-urlencode "To=whatsapp:+555551234567" \
  --data-urlencode "Url=http://demo.twilio.com/docs/voice.xml" \
  -u $TWILIO_ACCOUNT_SID:$TWILIO_AUTH_TOKEN
Place a call using Twilio Programmable Voice TwiML
You can initiate a call to WhatsApp numbers using the TwiML Voice <Dial> verb, similar to any other channel; there is a new <WhatsApp> noun to use, and the syntax to use for WhatsApp caller ID and destinations is whatsapp:{number}.

Note: All TwiML-generated calls to WhatsApp destinations must use a callerId attribute that is set to a WhatsApp sender that is registered and enabled for Voice calling on the Twilio account the call is being placed from. The format must be whatsapp:{sender}, as shown in the example below.


Copy code block
<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Dial callerId="whatsapp:+558551234567">
    <WhatsApp>+555551234567</WhatsApp>
  </Dial>
</Response>
Current restrictions to business-initiated calling


From WhatsApp
The call permission request can be sent at most once in 24 hours, and no more than two requests in seven days.
Users may approve, decline, not respond, or change their response before the request expires.
Once permission is granted, the business can place five calls per 24 hours, for a maximum of seven days before having to request permission again.
The call permission expires in these cases:
Seven days after it is approved, rejected, or not responded to.
A new call permission is requested and approved.
After two consecutive missed calls, the user will be prompted again to possibly change permission.
After four consecutive missed calls, permission will be automatically revoked.
The maximum number of concurrent calls to/from a WhatsApp sender is 1,000.
Calls to WhatsApp destinations cannot be connected to Public Switched Telephone Network (PSTN) endpoints.
From Twilio
The VOICE_CALL_REQUEST template does not require submission for WhatsApp approval.
In cases where you want to use text as part of the template, you must submit it for WhatsApp approval.
If you do not submit for approval, you cannot add any additional message text, and the template can be used only to send call permissions in existing sessions.
Connect WhatsApp Business Calling to Twilio Flex


To integrate WhatsApp Business Voice Calls with Twilio Flex, you'll need a TwiML application (as described above).

This will determine whether incoming calls are routed directly to Flex or through a Studio Flow (IVR) for additional processing.

Send calls straight to Flex


Navigate to TwiML Bins
.
Click on the + sign to create a new TwiML Bin. Use the following TwiML Bin:

Copy code block
<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Enqueue action="" method="POST" workflowSid="[TASKROUTER_WORKFLOW_SID]">call</Enqueue>
</Response>
Replace [TASKROUTER_WORKFLOW_SID] with the expected Workflow SID.

Save and copy the TwiML Bin URL.
Now that you have a TwiML Bin, you can create a TwiML application, as described above:

Navigate to TwiML Apps
.
Create a new TwiML application by clicking on Create a New TwiML App.
Give it a friendly name such as "WhatsApp Calling App".
In the Voice Configuration section, enter the URL of your TwiML Bin.
Click Create and then click again on the recently created TwiML application.
This TwiML application will be used to configure the Voice Configuration on your WhatsApp sender. If you are using the API to configure the sender, you'll want to copy the Application SID (APxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx). If you configure using the Console, you will want to remember the friendly name you gave the application.
Send calls to Flex using Studio


Navigate to TwiML Apps
.
Create a new TwiML application by clicking on Create a New TwiML App.
Give it a friendly name such as "WhatsApp Calling App".
In the Voice Configuration section, enter the URL of your Studio Flow:

Copy code block
https://webhooks.twilio.com/v1/Accounts/ACCOUNT_SID/Flows/STUDIO_FLOW_SID
Replace ACCOUNT_SID and STUDIO_FLOW_SID with your Account SID and the Studio Flow SID.

Click Create and then click again on the recently created TwiML application.
This TwiML application will be used to configure the Voice Configuration on your WhatsApp sender. If you are using the API to configure the sender, you'll want to copy the Application SID (APxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx). If you configure using the Console, you will want to remember the friendly name you gave the application.


.................


Elastic SIP Trunking


Getting Started: Configure your Twilio Elastic SIP Trunk


Before You Begin


In order to use Twilio Elastic SIP Trunking, you'll need a Twilio account. Sign up for a free Twilio account
 if you don't already have one.

Configure your Elastic SIP Trunk
Configure Trunks
General settings
Termination settings
Origination settings
Numbers
Connect your Network over
Public Internet
Twilio Interconnect
Twilio's IP addresses
Features
Codecs
Calls per Second
Call Recording
Secure Trunking
Call Redirect
Extended Call Duration
SIP Diversion Headers
Call Transfer via SIP REFER
Disaster Recovery URL
Emergency Calling
Caller Name: CNAM Lookup & CNAM Registration
Trusted Calling with STIR/SHAKEN
SIP Header Manipulation
Connect with your IP communications infrastructure:

Elastic SIP Trunking - Solution Blueprints
Elastic SIP Trunking - Configuration Guides
REST API documentation:

Elastic SIP Trunking REST API Reference
Requirements


In order to use Twilio Elastic SIP Trunking, you'll need to ensure that you have the following:

A SIP enabled network element (e.g. Session Border Controller, SIP Call Server, IP-PBX, SIP-PRI IAD, etc.) with access to the internet.

Sufficient Internet bandwidth to support the peak call traffic. The peak bandwidth can be determined by:

SIP Trunk Peak Bandwidth = Max Simultaneous Calls x 100 kbps
The 100 kbps value reflects the necessary bandwidth for the G711 codec plus sufficient room for overhead.

Dashboard


Log into the console and go to the "Elastic SIP Trunking" section. Your Dashboard will be displayed, providing a high level overview of your Trunking usage: Minutes, Calls & Cost.

On the left navigation menu you'll have links to:

Overview: Get started here, review tutorial docs, or access features & pricing.
Manage: Access Trunks, IP access control lists, credential lists, or networking info.
Manage


Under the "Manage" menu you will have access to all of the configuration aspects of your Trunks. Specifically, you will have links to:

Trunks: List of your existing SIP Trunks. Create, delete and configure your trunks.
IP Access Control Lists: Manage your IP Access Control Lists (a set of IPs that are allowed to reach your SIP Domain).
Credential Lists: Manage your user credentials (a set of usernames and passwords that are allowed to reach your SIP Domain).
Networking Info: Important information about Twilio's platform that you will need to configure your communications infrastructure.
Trunks


Twilio Elastic SIP Trunking is a cloud based solution that provides connectivity for IP-based communications infrastructure to connect to the PSTN, for making and receiving telephone calls to the 'rest of the world' via any broadband internet connection.

A trunk is composed of the following settings:

Diagram showing Elastic SIP Trunk connecting calls to cloud and phone network.
Expand image
General: Provide a friendly name for your trunk and see its unique identifier (Trunk SID).
Termination: Configure the settings for placing outgoing traffic from your communications infrastructure to the PSTN.
Origination: Configure the settings for receiving incoming traffic on your Twilio numbers to deliver calls to your communications infrastructure from the PSTN.
Numbers: Allows you to associate numbers with a given trunk, and see all numbers currently associated with a trunk.
From the Trunks navigation bar item you'll be able to view a full list of your Elastic SIP Trunks and click on each one to modify its configuration. You also have the ability to delete a given trunk from this view.

Create a Trunk


From the Trunks navigation bar click on "Create New Trunk" to create a new trunk. This may also be done from the Getting Started section.

General settings


These settings apply to the entire trunk regardless of the direction of your traffic.

Friendly Name
Provide a friendly name for your trunk.

Trunk SID
This is the unique identifier of this trunk, and is assigned automatically once you create a trunk.

Call Recording
From this drop-down you can enable call recording for this trunk. When enabled, all calls are recorded (both origination and termination traffic), in a pay-as-you-go consumption model. Recording options for a single channel or dual channels can be selected. The default setting of a trunk is Do Not Record. You can select:

Do Not Record: Recording is disabled on this trunk.
Record from ringing: Recording will begin when the ringing starts.
Record from answer: Recording will begin when a call is answered.
Dual Record from ringing: Recording will begin when the ringing starts and both tracks will be visualized separately.
Dual Record from answer: Recording will begin when a call is answered and both tracks will be visualized separately.
Recording Trim: If enabled, silence will be trimmed from the recording. If disabled, silence will not be trimmed from the recording.
Extended Call Duration
Twilio extended the maximum call duration on Elastic SIP Trunking calls from 4 hours to 24 hours. This allows the business to have extended conversations that last longer than 4 hours. You can see details here.

Secure Trunking
Encryption ensures that the call media and associated signalling remains private during transmission. Transport Layer Security (TLS) provides encryption for SIP signaling and Secure Real-time Transport Protocol (SRTP) provides encryption for call content/media packets. Learn about how to enable and troubleshoot TLS issues from this blog.

The TLS protocol is designed to establish a secure connection between a client and a server communicating over an insecure channel. RFC 5246, the Transport Layer Security (TLS) Protocol, Version 1.2, specifies Version 1.2 of the Transport Layer Security (TLS) protocol.

TLS Specifications:

Supported TLS versions: TLSv1.2 and above.
To comply with industry-standard security requirements, Twilio no longer supports TLSv1.0 and TLSv1.1 for inbound or outbound Elastic SIP Trunking calls and SIP registration.
Supported Ciphers: ECDHE-RSA-AES128-GCM-SHA256, ECDHE-RSA-AES128-SHA256, ECDHE-RSA-AES256-GCM-SHA384, ECDHE-RSA-AES256-SHA384,AES128-GCM-SHA256,AES128-SHA256,AES128-SHA,AES256-GCM-SHA384,AES256-SHA256,AES256-SHA
Note: When TLS is enabled, you will no longer be able to view the SIP signalling packets in the PCAP captures within the Call Logs section.

SRTP provides a framework for the encryption of RTP & RTCP. RFC 4568, Session Description Protocol (SDP) Security Description (SDES) for Media Streams, defines such a protocol specifically designed to exchange cryptographic material using a newly defined SDP crypto attribute.

SRTP Specifications:

Trunking Origination: Only a single crypto suite will be included: AES_CM_128_HMAC_SHA1_80
Trunking Termination: Crypto suites supported include AES_CM_128_HMAC_SHA1_80 and AES_CM_128_HMAC_SHA1_32. Both may be included in an order of preference.
The optional master key identifier (MKI) parameter is not supported
When Secure Trunking is enabled, any non-encrypted calls will be rejected. Please ensure you configure the use of TLS in your Origination Settings by including the transport=tls parameter. If the transport parameter is present on any of your URIs specifying a different transport (e.g. transport=udp), it will be ignored and TLS will be used. By default port 5061 will be used for TLS, however you may specify the port you wish to use in your Origination URI.

Importing Twilio's Root CA Certificate
TLS is used to encrypt SIP signaling between SIP endpoints. In order for this to function properly, devices in your network that communicate directly with Twilio must be configured to trust Twilio's TLS/SSL Certificate. Twilio uses certificates issued by a CA (Certificate Authority). You may need to add additional root certificates to your communications infrastructure to establish the authenticity of Twilio's certificate on the network. Download Twilio's bundle of trusted CA certificates
. (Last updated September 1, 2023).

Note: the current bundle contains the following root certificates:

DigiCert Global Root CA
DigiCert Global Root G2
DigiCert Global Root G3
Please be aware that the Twilio CA bundle may be updated in the future, for example when root certificates expire or are distrusted by the CA. In such cases we will notify you to update your SIP devices. Please ensure that your email address is up to date in your account information to ensure you receive such communication.

TLS/SRTP support with Asterisk
Asterisk ships by default with chan_sip driver and works well with Twilio. However, if you have some reason to run PJSIP driver with Asterisk, note the following:

Asterisk 13.8 cert2 defaults to PJSIP 2.5 and it does not work with Twilio for TLS/SRTP purposes. Non-encrypted calls do work
Asterisk 13.8 cert2 can also use the latest PJSIP driver, which at this time is 2.5.5. Twilio works well with it despite the following message appearing in your log:
PJSIP 2.5.5 outputs the following error but the call is still shown to work.


Copy code block
Sep 27 13:03:56] ERROR[10886]: pjproject:0 :     tlsc0x7f217c03 RFC 5922 (section 7.2) does not allow TLS wildcard certificates. Advise your SIP provider, please!
The following link is a guide to installing a non-bundled version of PJSIP. Change the version to 2.5.5 in the steps.

Installing PJSIP channel driver

Call Transfer via SIP REFER
When Call Transfer is enabled, Twilio will consume an incoming SIP REFER from your communications infrastructure and create an INVITE message to the address in the Refer-To header. Please go here for more details.

Media Settings
Symmetric RTP
In general, your IP communications infrastructure should use your public IP address in the SDP and that will be the ONLY destination where Twilio will send media towards. However, if you're traversing a non-SIP aware NAT, you may not know your public IP and your SDP will include your private IP address, typically leading to one-way audio issues. Twilio is able to resolve this by latching onto the incoming RTP media stream and sending RTP towards that destination by enabling Symmetric RTP.

When Symmetric RTP is enabled Twilio will detect where the remote RTP stream is coming from and start sending RTP to that destination instead of the one negotiated in the SDP. This setting is more vulnerable to RTP attacks.

When Symmetric RTP is disabled, Twilio will send RTP to the destination negotiated in the SDP. This setting is considered to be more secure and therefore recommended.

Termination Settings


Configuring your termination settings will allow you to place outgoing traffic from your communications infrastructure to the PSTN. In order to use a trunk for termination it must have a Termination SIP URI and at least one authentication scheme (IP Access Control Lists and/or Credentials Lists).

Elastic SIP Trunking connects calls to a cloud service and phone network.
Expand image
Termination URI
Configure a SIP Domain Name to uniquely identify your Termination SIP URI for this trunk. This URI will be used by your communications infrastructure to direct SIP traffic towards Twilio.

{example}.pstn.twilio.com
Twilio recommends that you use a dash instead of a dot to improve readability of your domain. However, in some cases you may prefer a sub-domain like a.b.pstn.twilio.com of the higher-level domain b.pstn.twilio.com

A sub-domain like a.b.pstn.twilio.com can be created under the following requirements:

The higher-level domain (b.pstn.twilio.com) must be created first
The higher-level domain (b.pstn.twilio.com) must be created by the same account or the parent account
Configure a trunk on your communications infrastructure (e.g. IP-PBX or SBC)
Configure a trunk on your communications infrastructure and point it towards {example}.pstn.twilio.com for outbound traffic towards Twilio.

Localized Termination URIs
If you wish to manually connect to a specific geographic edge location that is closest to the location of your communications infrastructure, you may do so by pointing your communications infrastructure to any of the following localized Termination SIP URIs:

{example}.pstn.ashburn.twilio.com (North America Virginia)
{example}.pstn.umatilla.twilio.com (North America Oregon)
{example}.pstn.dublin.twilio.com (Europe Ireland)
{example}.pstn.frankfurt.twilio.com (Europe Frankfurt)
{example}.pstn.singapore.twilio.com (Asia Pacific Singapore)
{example}.pstn.tokyo.twilio.com (Asia Pacific Tokyo)
{example}.pstn.sao-paulo.twilio.com (South America São Paulo)
{example}.pstn.sydney.twilio.com (Asia Pacific Sydney)
(information)
Info
You can find the legacy localized URIs list here. eg: {example}.pstn.us1.twilio.com

Redundancy with Termination URIs
Twilio's Elastic SIP Trunking uses an FQDN ({example}.pstn.twilio.com) as a Termination URI that is used by your communications infrastructure to direct SIP traffic towards Twilio. As explained in the previous section, localized Termination URIs are available.

For example, {example}.pstn.ashburn.twilio.com, this specific FQDN resolves in the following DNS A-Record:

Type	IP Address	TTL
A	54.172.60.3	10 min
A	54.172.60.0	10 min
A	54.172.60.2	10 min
A	54.172.60.1	10 min
For each edge location we have 3-4 IP addresses that are used for reliability purposes (see IP addresses. Each of these IP addresses represents a unique public edge for our Elastic SIP Trunking services into the Twilio cloud, distributed across multiple Availability Zones for reliability purposes.

We strongly recommend that you avoid directing your SIP traffic to a single IP address. Instead, utilize all available IP addresses and implement failover in case one IP is not responding. For more information, review our Best Practices for Sending SIP to Twilio.

A common strategy, which we deploy internally and what we have instructed our carriers to do towards us as well, is that if there is no response to an INVITE, go to the next IP after 4 seconds. A single machine behind a single IP will always fail at some point so the overall solution must take that into consideration and guard itself towards these failures.

Furthermore, if there is a complete Ashburn outage, it is recommended that you failover to another edge location (e.g. If connecting to ashburn, failover to umatilla), keeping in mind that the Edge Location will in turn resolve to 3-4 different IP addresses for reliability.

Authentication
Configure the authentication details to ensure the security/authenticity of your termination traffic. You must configure a minimum of either an ACL or credential authentication. If you configure both, then both ACLs and credentials are enforced.

(information)
Info
It is highly recommended that you configure User Credentials. IP ACL's alone does not protect against certain types of attacks.

To create a new Access Control List (ACL):

Click "Create IP Access Control List" from the "Authentication" section.
Give the Access Control List a friendly name that is descriptive of what that list of IPs. Something like "Dallas Datacenter IPs".
Add IPs to your new IP Access Control List (these should be the IP addresses used for outbound SIP traffic by your Communications Infrastructure border elements, e.g. SBC).
Give your IPs a friendly name that is descriptive of what that IP is, for example "Production SBC".
Click "Create ACL"
To create a new Credential List:

Click "Create Credential List" from the "Authentication" section.
Give the Credential List a friendly name that is descriptive of the user you're authenticating. Something like "Admin, Twilio".
Enter a username (these should be the username used for digest authentication for outbound SIP traffic by your communications infrastructure border elements, e.g. SBC).
Enter the corresponding password for that user.
Click "Create Credentials List"
If you are using User Credentials, your SIP INVITE will be challenged with a 407 Proxy Authentication Required requesting the appropriate user credentials.

By the end of this step your trunk will be able to process termination calls from your communications infrastructure, via Twilio, to the PSTN.

Allowed Caller ID Numbers in Termination calls
You must specify a Caller ID Number that either corresponds to a Twilio DID on your account or a Caller ID Number that has been verified on the Console
 or with the Outgoing Caller ID API.

If a Caller ID Number is not specified in the SIP INVITE's From Field, then the Remote-Party-ID or the P-Asserted-Identity will be used.

(information)
Info
For Trial accounts, in addition to using a verified Caller ID, you can only call numbers that are also verified. To remove this restriction, Upgrade your account via the Console
.

Make your first Termination call
INVITE sip:+15108675309@{example}.pstn.ashburn.twilio.com SIP/2.0

Make sure that any phone numbers sent via SIP to Twilio are always
E.164-formatted (e.g.+12128675309). If E.164 format is not used, then the
call will be rejected with a SIP 400 Bad Request response.

(warning)
Warning
Make sure your E.164 formatted number always includes +. This plus prefix is a must.

Origination settings


Configuring your origination settings will allow you to receive incoming traffic from the PSTN to a Twilio number, delivered to your communications infrastructure. With phone numbers available in over 100 countries, Twilio gives you a truly global SIP Trunk. A minimum of one Twilio number should be associated with this trunk if you're configuring it for origination.

Diagram showing call flow through Elastic SIP Trunk to Twilio cloud and phone endpoint.
Expand image
The origination settings configured in this section will apply to all numbers associated with this trunk.

Origination SIP URI
Configure your origination SIP URI, which identifies the network element entry point into your communications infrastructure (e.g. IP-PBX, SBC). The host part of the SIP URI may be either an IP address or a Fully Qualified Domain Name (FQDN).

sip:172.56.42.132
sip:mysbc.com
Twilio will automatically populate the user part of the SIP URI based on the Twilio number the call from the PSTN is destined towards. For example, if the call from the PSTN is received for Twilio number +14158675309, which is associated with this trunk, the resulting URI sent to your communications infrastructure will be:

sip:+14158675309@172.56.42.132
sip:+14158675309@mysbc.com
Alternatively, you may also configure a specific user-part (e.g. "anniebp") within the origination SIP URI. Note that the same URI will be used for all Numbers associated with this trunk. Hence, if the call from the PSTN is received for Twilio number +14158675309, which is associated with this trunk, the resulting URI towards your communications infrastructure will still be the following for all phone numbers:

sip:anniebp@172.56.42.132
sip:anniebp@mysbc.com
Note: The Twilio number dialed (+14158675309) will always be conveyed in a SIP Diversion header for Trunking Origination calls.

X-headers
It is possible to send any SIP header beginning with the X- prefix, by appending them to the origination SIP URI. For example, you could configure: sip:+14158675309@mysbc.com?X-myheader=foo to send X-myheader:foo on all originated calls.

The transport parameter
By default, Twilio sends originating SIP requests towards your communications infrastructure over UDP. This may be customized to be sent over TCP rather than UDP. Change this by using the transport parameter in the origination SIP URI:

sip:anniebp@172.56.42.132;transport=tcp
Alternatively, you may customize it to use TLS for SIP signalling. When using TLS, the default port will be 5061, however a different one may be specified. Change this by using the transport parameter in the origination SIP URI, and optionally by specifying a different port number:

sip:anniebp@172.56.42.132:5062;transport=tls
(information)
Info
Note: Elastic SIP Trunking Origination URI configurations using the sips URI scheme in order to enable end-to-end encryption is NOT supported by Twilio. However, we do support sip URI schemes using transport=tls for point-to-point encryption.

If you configure your Elastic SIP Trunking Origination URIs to use sips schemes, these sips URIs will be handled as if they were sip URIs using TLS transport. Twilio will effectively adjust the URI internally to instead be routed using the sip scheme and transport=tls on the outbound messages, resulting in point-to-point encryption between Twilio and the customer equipment.

Twilio strongly suggests not using sips schemes in your Twilio SIP configurations, as this could cause possibly unintended behavior, due to how we process such URIs. Instead, we suggest using sip schemes with TLS transport. This method, along with the security of our voice architecture and Super Network, is an effective way of adding encryption to your Twilio SIP connections.

The edge parameter
To specify the geographic edge from which Twilio will send the originating SIP traffic towards your communication infrastructure, you must include the edge parameter in your Origination SIP URI. For example, if the edge=dublin parameter is included in your Origination SIP URI, Twilio will send the SIP traffic from the Europe Ireland edge location:

sip:anniebp@172.56.42.132;edge=dublin
If the edge parameter is not specified or is incorrect, Twilio will send the Originating SIP traffic from the edge location where the incoming PSTN call comes in.

Note: You must make sure you allow the IP addresses of the Twilio edge location for SIP signalling and RTP media traffic.

(information)
Info
This parameter was previously named region and it is still supported. View a list of legacy region identifiers here. eg: sip:anniebp@172.56.42.132;region=ie1

Using Multiple Origination SIP URIs
It is possible to configure up to ten (10) Origination SIP URIs with different priority & weight.

The priority field determines the precedence of use of the SIP URI. Twilio will always use the SIP URI with the lowest-numbered priority value first, and fallback to other SIP URIs of equal or higher value if the session to that SIP URI fails.

If a service has multiple origination SIP URIs with the same priority value, Twilio will use the weight field to determine which SIP URI to use. The weight value is relevant only in relation to other SIP URIs with the same priority value.

Priority ranks the importance of the URI. Values range from 0 to 65535, where the lowest number represents the highest importance. Weight is used to determine the share of load when more than one URI has the same priority. Its values range from 1 to 65535. The higher the value, the more load a URI is given.

It is possible to enable or disable an origination SIP URI. When an origination SIP URI is enabled, it's active in the route selection. If it is not enabled, then it will not be used for routing traffic towards your communications infrastructure.

In the following example, both the priority and weight fields are used to provide a combination of load balancing and failover services.

Origination SIP URI	Priority	Weight
sip:mysbc1.com	10	60
sip:mysbc2.com	10	20
sip:mysbc3.com	10	20
sip:mysbc-backup.com	20	10
The first three SIP URIs share a priority of 10, so the weight field's value will be used Twilio to determine which server to contact. The sum of all three values is 100, so sip:mysbc1.com will be used 60% of the time. The two SIP URIs sip:mysbc2.com and sip:mysbc3.com will be used for 20% of requests each. If sip:mysbc1.com is unavailable, these two remaining machines will share the load equally, since they will each be selected 50% of the time.

If all three servers with priority 10 are unavailable, the record with the next lowest priority value will be chosen, which is sip:mysbc-backup.com. Note: If any of the following SIP status codes are returned ("2xx", "400", "404", "405", "410", "416", "482", "484", "486", "6xx"), Twilio will not fail over to the next origination SIP URI. If there is no SIP response from a given server, Twilio will fail over after 4 seconds.

Disaster Recovery URL
In the case of a disaster preventing your calls from being delivered to your origination SIP URI above, you can configure a Disaster Recovery URL pointing to an application built on Twilio's powerful scripting tool called TwiML. You can use TwiML to build an application that will manage calls as required by your disaster recovery plan, including replicating the functionality of your PBX (e.g. IVR).

http://fallback.example.com/index
For more information on building your TwiML application, please refer to the Twilio QuickStart and TwiML API Guide. When calls are redirected to your disaster recovery URL, normal Twilio Voice rates apply: see voice pricing.

CNAM Lookups
CNAM is an acronym which stands for Caller ID Name. CNAM is used to display the calling party's name alongside the phone number, to help users easily identify a caller.

When you enable CNAM Lookup, the Caller ID Name is inserted in the SIP INVITE via the "From", and "Contact" and (if applicable) "P-Asserted-Identity" fields for each caller.

Note that CNAM lookups for US/CA numbers are billed per lookup, even if data may not be available. Currently, requesting Caller ID Name Lookup for international numbers will return null values, but will not be billed.

Enable this Feature Using the Twilio Console
To enable CNAM Lookup using the console, log into the console and go to the "Elastic SIP Trunking" section.

When you have selected a Trunk, navigate to the "Origination" Settings (via the left-hand sub-menu). Here, you will see a switch where you can enable CNAM Lookup. You will know the setting has been enabled when the switch has turned 'blue' and the word 'ENABLED' appears.

CNAM Lookup must be enabled on a per Trunk basis
CNAM Lookup is only supported for US/CA phone numbers
CNAM Lookup is billed per successful lookup (this includes the case where the Name is not available for a Number in the CNAM National databases). It is known that many AT&T numbers are not published to the CNAM National databases.
CNAM Lookup is billed per successful lookup, even if the call itself fails
Call Redirect
Call redirect enables you to redirect a Trunking Origination call. Your communications infrastructure can redirect an incoming INVITE by responding with a SIP 302 (Moved Temporarily). This response contains a contact header field with the new addresses that should be tried.

Twilio supports a single redirection per call:
If a redirected target also sends a SIP 302 response to another target, Twilio will fail the call.
Twilio honors the first URI of the SIP 302 response: Multiple URIs in the SIP Contact header except the first one or multiple SIP Contact headers except the first one will be ignored.
Call redirections towards Twilio domains (*.sip.twilio.com or *.pstn.twilio.com) are not supported
If the call is to a registered SIP endpoint, redirection is not allowed
The edge parameter is not supported in a SIP 302 contact URI. The redirected call will use the same egress edge location as the original call
The tnx parameter is not supported in a SIP 302 contact URI. The redirected call will use the same Interconnect Connection as the original call
If Secure Trunking was used for the original INVITE then the redirected call will also use TLS/SRTP
If Call Recording was used for the original INVITE then the redirected call will also be recorded
SIP Diversion Headers



Trunking Origination
When Twilio receives incoming traffic on your Twilio numbers from the PSTN to be directed to your communications infrastructure, it will add a SIP Diversion header noting the Twilio number that was dialed. This header serves as a historical record that indicates that the call was diverted from the dialed number to the Origination SIP URI of your SIP Trunk. An example of what this Diversion header might look like is shown below.

Diversion: <sip:+14155550000@twilio.com>

Trunking Termination
When Twilio receives outgoing traffic from your communications infrastructure to the PSTN, your SIP message can sometimes include SIP Diversion headers if the call was previously forwarded. Twilio will forward SIP Diversion headers it receives to the carriers.

To combat any malicious addition of Diversion headers, Twilio will check all Diversion headers it receives that contain the Twilio domain. Twilio will verify that the phone number included in the header matches one associated with your Twilio account (either a Twilio number owned by the account or a verified Caller ID). If the header fails this check, Twilio will remove the header.

Numbers


From this tab you will be able to:

Buy a new Twilio Number for your Trunk
View all Twilio Numbers currently associated with this Trunk
Associate an existing Twilio Number with this Trunk
Disassociate a Twilio Number from this Trunk
View all Twilio Numbers currently associated with this Trunk
In the "Numbers" section you will be able to view all numbers currently
associated with this trunk. Recall that all of these numbers share the same
origination & general settings.

You may click on a given number to view/modify its configuration.

Buy a new Twilio number for your trunk
A minimum of a single Twilio Phone Number is required to be able to receive
incoming calls from the PSTN to your communications infrastructure via your
Twilio Trunk.

Make sure you have all your trunk configuration changes saved, and then from
the "Numbers" section select "Buy a Number".

Select the country code, and search for available numbers matching any patterns
(e.g. +14158675309) you might want to look for in your number.

Once you find the Twilio number you would like to buy, go ahead and purchase it
and continue to set up your number.

This will take you to the number view where you can modify the configuration
for that number.

Under the "Voice" section select the "SIP Trunking" radio button, and from the
dropdown list below select the desired SIP Trunk you would like to associate
this Number with. Don't forget to save your configuration changes.

Associate an existing Twilio number with this trunk
In the "Numbers" section select "Associate a Number with this Trunk", which
will display a list of all of your existing Twilio numbers. Click on the one
you would like to associate with this trunk.

This will take you to the number view where you can modify that number's
configuration. Under the "Voice" section, select the "SIP Trunking" radio
button, and from the dropdown list below select the desired SIP Trunk you would
like to associate this number with. Don't forget to save your configuration
changes.

Disassociate a Twilio Number from this Trunk
You can disassociate a number from a trunk in several ways:

From the "Numbers" section of a given trunk, you can directly disassociate a
phone number from the numbers list displayed by clicking on the trash button.
By changing the "Voice" configuration of a given number to a different trunk
or by configuring it with an application or URL
By deleting the trunk associated with that number
Note that when you do this, the number is disassociated from the trunk but it
is not released from your account.

Twilio phone numbers are billed on a monthly basis. Unless you are actively
using a number, or you want to keep a number reserved for future use, you can
reduce your costs by releasing your unused numbers. In order to release the
number, go to the "Voice and Messaging" section, click on "Numbers" and
release the desired number from that page.

Receive your first origination call
Make your first test call by dialing your trunk's Twilio number, e.g. +14158675309, and ensure your corresponding communications infrastructure extension rings.

Delete a Trunk


You can delete a trunk:

From the "Trunks" section, using the trunks list displayed. Note that when you do this, all numbers associated with this trunk will be automatically disassociated from the trunk but not released. In order to release it please go to the "Voice and Messaging" section, click on "Numbers" and release the desired numbers from that section.
From any of the trunk specific configuration screens you will have the option to "Delete this Trunk".
Note that when you do this, all numbers previously associated with this trunk will be disassociated from the trunk, but they will not be released from your account. Twilio phone numbers are billed on a monthly basis. Unless you are actively using a number, or you want to keep a number reserved for future use, you can reduce your costs by releasing your unused numbers. In order to release the number, please go to the "Voice and Messaging" section, click on "Numbers" and release the desired number from that section.

Your Network


Prepare your communications infrastructure to make sure that your SIP infrastructure has connectivity to Twilio and vice versa.

Configure your Termination URIs for your Twilio Trunk, optionally using a Localized Termination URI if you wish to manually connect to a specific geographic edge location of the Twilio platform.
Allow all of Twilio's signalling and media IP addresses and ports on your firewall.
Configure your infrastructure not to register for this trunk.
Ensure that your infrastructure sends a value of 70 for the Max-Forwards header per RFC 3261 section 8.1.1.6, to ensure your call is processed successfully.
Ensure that any phone numbers sent via SIP to Twilio are always E.164-formatted.
Optionally set-up your Communications Infrastructure to issue SIP OPTIONS messages as a ping mechanism to your Elastic SIP Trunk (Send the Message Request To: Termination URI you created (example.pstn.twilio.com)); the Twilio platform will respond appropriately. Please maintain the Ping lower than 1 SIP OPTIONS every 10-15 seconds to avoid your requests from being banned by our Platform.
Deploying behind a NAT
If you're deploying behind a NAT without a Session Border Controller, it's important to keep open the NAT translation binding.

For Signaling, when using UDP, this may be achieved by periodically sending SIP OPTIONS to Twilio, which will respond with a 200OK.
For Signaling, when using TCP or TLS, this may be achieved by periodically sending SIP OPTIONS to Twilio, or CR-LF keep-alives (periodically sending a double-CRLF (the "ping") then wait to receive a single CRLF (the "pong") from Twilio), the latter has the smallest overhead.
For RTP, this is usually less of an issue as media packets are sent more frequently.
IP addresses
You MUST allow ALL of Twilio's following IP address ranges and ports on your firewall for SIP signalling and RTP media traffic. This is important if you have Numbers in different edge locations and for resiliency purposes (e.g. if North America Virginia gateways are down, then North America Oregon gateways will be used). Twilio does not guarantee which edge location the media will egress from, without using the edge parameter since it can depend on which PSTN-SIP Gateway delivers the call to which Twilio edge location.

Please see Twilio's Elastic SIP Trunking IP addresses for the complete list.

For further information to help you configure your infrastructure with your Twilio Elastic SIP Trunk, refer to the SIP Trunking configuration guides.


.............


Sim — SIP é o caminho mais simples para “WhatsApp call inbound no Twilio → OpenAI Realtime”, porque você não precisa fazer ponte de áudio via WebSocket (Media Streams). O fluxo fica:

WhatsApp → Twilio Voice (webhook/TwiML) → SIP INVITE para OpenAI → OpenAI dispara realtime.call.incoming → seu servidor chama POST /realtime/calls/{call_id}/accept. 
Twilio
+2
OpenAI Platform
+2

1) Twilio: receber ligação do WhatsApp e mandar para SIP (OpenAI)

Ative o WhatsApp Business Calling no seu WhatsApp Sender configurando voice_application_sid (TwiML App). A própria doc diz que isso “ativa” chamadas nesse sender. 
Twilio

Quando chegar uma ligação no seu WhatsApp Sender, o Twilio vai chamar o webhook do seu Twilio Voice App “como se fosse” uma inbound call normal. 
Twilio

Nesse webhook, responda com TwiML dialando o SIP do OpenAI:

<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Dial>
    <Sip>sip:proj_SEU_PROJECT_ID@sip.api.openai.com;transport=tls;region=br1</Sip>
  </Dial>
</Response>


O SIP do OpenAI é nesse formato: sip:$PROJECT_ID@sip.api.openai.com;transport=tls (o project id tem prefixo proj_). 
OpenAI Platform

Twilio suporta <Dial><Sip> e o parâmetro region (ex.: br1 São Paulo) no SIP URI. 
Twilio

Twilio documenta ;transport=tls em SIP URI. 
Twilio

Nota importante: chamadas vindas de endpoints WhatsApp não podem ser conectadas a PSTN (telefone comum) — portanto SIP/WebRTC ok; PSTN não. 
Twilio

2) OpenAI: webhook + aceitar a chamada

No OpenAI Console, crie um webhook do seu Project para o evento realtime.call.incoming. 
OpenAI Platform

Quando o webhook chegar, você deve aceitar a chamada com:

POST https://api.openai.com/v1/realtime/calls/{call_id}/accept 
OpenAI Platform
+1

Exemplo (curl oficial da doc):

curl -X POST "https://api.openai.com/v1/realtime/calls/$CALL_ID/accept" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "type": "realtime",
        "model": "gpt-realtime",
        "instructions": "Atenda em pt-BR e seja objetivo."
      }'


OpenAI Platform

3) Exemplo mínimo (Node/Express) do webhook realtime.call.incoming

A doc oficial recomenda validar assinatura (Standard Webhooks) e mostra webhooks.unwrap(...) no SDK. 
OpenAI Platform
+1

import express from "express";
import OpenAI from "openai";

const app = express();

// Importante: usar corpo "raw" para validar assinatura
app.use(express.text({ type: "application/json" }));

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  webhookSecret: process.env.OPENAI_WEBHOOK_SECRET,
});

app.post("/openai/webhook", async (req, res) => {
  let event;
  try {
    event = await client.webhooks.unwrap(req.body, req.headers);
  } catch (e) {
    return res.status(400).send("Invalid signature");
  }

  if (event.type === "realtime.call.incoming") {
    const callId = event.data.call_id;

    const r = await fetch(`https://api.openai.com/v1/realtime/calls/${callId}/accept`, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        type: "realtime",
        model: "gpt-realtime",
        instructions: "Atenda em pt-BR. Seja claro e objetivo.",
      }),
    });

    if (!r.ok) {
      // logue r.status / body conforme seu padrão
    }
  }

  res.status(200).send();
});

app.listen(8000, () => console.log("listening on 8000"));
